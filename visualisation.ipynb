{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize testing data TuSimple\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "color_map = {\n",
    "    0: [0,0,0], #black\n",
    "    1: [255, 0, 0],  # Blue\n",
    "    2: [0, 255, 0],  # Green\n",
    "    3: [0, 0, 255],  # Red\n",
    "    4: [0, 255, 255]  # Yellow\n",
    "}\n",
    "\n",
    "def gt_preprocess(gt_h, gt_lanes):\n",
    "    coor_list = []\n",
    "    for lane in gt_lanes:\n",
    "        coordinates = list(zip(lane, gt_h))\n",
    "        coor_list.append(coordinates)\n",
    "    return coor_list\n",
    "\n",
    "# change accordingly\n",
    "gt_parent = \"/home/automan/wuguanjie/TuSimple/train/test_label_new.json\"\n",
    "saving_file_path = \"/home/automan/wuguanjie/exp_TU_baseline_flip_sr2211_GELU_se_RANSAC\"\n",
    "pred_parent = \"/home/automan/wuguanjie/SCNN_Pytorch/experiments/exp_TU_baseline_flip_sr2211_GELU_se/coord_output\"\n",
    "im_parent = \"/home/automan/wuguanjie/TuSimple/test/clips\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open(gt_parent) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        gt_data = json.loads(line)\n",
    "        gt_path = gt_data[\"raw_file\"]\n",
    "        path_tail = gt_path.split(os.path.sep)[-3:-1]\n",
    "        im_path = os.path.join(im_parent,*path_tail,\"20.jpg\")\n",
    "        pred_img = cv2.imread(im_path)\n",
    "        gt_img = pred_img.copy()\n",
    "        gt_h = gt_data[\"h_samples\"]\n",
    "        gt_lanes = gt_data[\"lanes\"]\n",
    "        lane_idx = gt_data[\"lane_idx\"]\n",
    "        gt_coor = gt_preprocess(gt_h, gt_lanes)\n",
    "        for i in range(len(gt_coor)):\n",
    "            coordinates = gt_coor[i]\n",
    "            lane_color = lane_idx[i]\n",
    "            colour = color_map[lane_color]\n",
    "            for idx in range(len(coordinates)):\n",
    "                if (idx+1) < len(coordinates):\n",
    "                    current_x, current_y = coordinates[idx][0],coordinates[idx][1]\n",
    "                    next_x, next_y = coordinates[idx+1][0],coordinates[idx+1][1]\n",
    "                    if current_x == -2 or next_x == -2:\n",
    "                        continue\n",
    "                    else: \n",
    "                        cv2.line(gt_img, (current_x,current_y), (next_x,next_y) , colour, 3)\n",
    "\n",
    "        pred_file = os.path.join(pred_parent, *path_tail,\"20.lines.txt\")\n",
    "        with open (pred_file) as f:\n",
    "            lines = f.readlines()\n",
    "            lane_idx = lines[-1].split(\" \")\n",
    "            for line, lane_color in iter(zip(lines[:-1],lane_idx)):\n",
    "                colour = color_map[int(lane_color)]\n",
    "                coordinates = iter(line.split(\" \"))\n",
    "                coordinates = list(zip(coordinates, coordinates))\n",
    "                coordinates = np.array(coordinates,dtype =np.float).astype(int)\n",
    "\n",
    "                for x,y in coordinates:\n",
    "                    for idx in range(len(coordinates)):\n",
    "                        if (idx+1) < len(coordinates):\n",
    "                            current_x, current_y = coordinates[idx][0],coordinates[idx][1]\n",
    "                            next_x, next_y = coordinates[idx+1][0],coordinates[idx+1][1]\n",
    "                            if current_x == -1 or next_x == -1:\n",
    "                                continue\n",
    "                            else: \n",
    "                                cv2.line(pred_img, (current_x,current_y), (next_x,next_y) , colour, 3)\n",
    "        vis = np.concatenate((pred_img, gt_img), axis=1)\n",
    "        if not os.path.exists(saving_file_path):\n",
    "            os.makedirs(saving_file_path)\n",
    "        saving_path = os.path.join(saving_file_path, str(path_tail[-1])+\".jpg\")\n",
    "        cv2.imwrite(saving_path, vis)\n",
    "        # count += 1\n",
    "        # if count == 3:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising training data\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "color_map = {\n",
    "    0: [0,0,0], #black\n",
    "    1: [255, 0, 0],  # Blue\n",
    "    2: [0, 255, 0],  # Green\n",
    "    3: [0, 0, 255],  # Red\n",
    "    4: [0, 255, 255]  # Yellow\n",
    "}\n",
    "\n",
    "def gt_preprocess(gt_h, gt_lanes):\n",
    "    coor_list = []\n",
    "    for lane in gt_lanes:\n",
    "        coordinates = list(zip(lane, gt_h))\n",
    "        coor_list.append(coordinates)\n",
    "    return coor_list\n",
    "\n",
    "\n",
    "gt_parent = \"/home/automan/wuguanjie/TuSimple/train/label_data_0601_new.json\"\n",
    "saving_file_path = \"/home/automan/wuguanjie/TuSimpleTrainingVis\"\n",
    "im_parent = \"/home/automan/wuguanjie/TuSimple/train\"\n",
    "count =0\n",
    "with open(gt_parent) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        gt_data = json.loads(line)\n",
    "        count+=1\n",
    "        gt_path = gt_data[\"raw_file\"]\n",
    "        im_path = os.path.join(im_parent,gt_path)\n",
    "        path_tail = gt_path.split(os.path.sep)[-3:-1]\n",
    "        pred_img = cv2.imread(im_path)\n",
    "        gt_img = pred_img.copy()\n",
    "        gt_h = gt_data[\"h_samples\"]\n",
    "        gt_lanes = gt_data[\"lanes\"]\n",
    "        lane_idx = gt_data[\"lane_idx\"]\n",
    "        gt_coor = gt_preprocess(gt_h, gt_lanes)\n",
    "        colours = [(255,0,0), (0,255,0), (255,0,255),(255,255,0), (128,0,128) ]\n",
    "        colour_index = 0\n",
    "        for i in range(len(gt_coor)):\n",
    "            coordinates = gt_coor[i]\n",
    "            lane_color = lane_idx[i]\n",
    "            colour = color_map[lane_color]\n",
    "            for idx in range(len(coordinates)):\n",
    "                if (idx+1) < len(coordinates):\n",
    "                    current_x, current_y = coordinates[idx][0],coordinates[idx][1]\n",
    "                    next_x, next_y = coordinates[idx+1][0],coordinates[idx+1][1]\n",
    "                    if current_x == -2 or next_x == -2:\n",
    "                        continue\n",
    "                    else: \n",
    "                        cv2.line(gt_img, (current_x,current_y), (next_x,next_y) , colour, 3)\n",
    "            colour_index += 1\n",
    "        colour_index = 0\n",
    "        if not os.path.exists(saving_file_path):\n",
    "            os.makedirs(saving_file_path)\n",
    "        saving_path = os.path.join(saving_file_path,path_tail[0]+\"_\"+path_tail[1]+\"_\"+\"20.jpg\")\n",
    "        cv2.imwrite(saving_path, gt_img)\n",
    "        # if count == 1:\n",
    "        #     break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing CuLane testing data\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "color_map = {\n",
    "    0: [0,0,0], #black\n",
    "    1: [255, 0, 0],  # Blue\n",
    "    2: [0, 255, 0],  # Green\n",
    "    3: [0, 0, 255],  # Red\n",
    "    4: [0, 255, 255]  # Yellow\n",
    "}\n",
    "\n",
    "def check_lane_idx(coor_list):\n",
    "    slope = []\n",
    "\n",
    "    #calculate slope\n",
    "    for i in range(len(coor_list)):\n",
    "        coor = coor_list[i]\n",
    "        slope.append(np.arctan2(coor[0][1] - coor[-1][1], coor[-1][0] - coor[0][0])/ np.pi* 180)\n",
    "    coor_list = [coor_list[i] for i in np.argsort(slope)]\n",
    "    slope = [slope[i] for i in np.argsort(slope)]\n",
    "    #create new coor_list\n",
    "    new_coor_list = []\n",
    "    idx_list = [None, None, None, None]\n",
    "    for i in range(len(slope)):\n",
    "        if slope[i] <= 90:\n",
    "            idx_list[1] = i\n",
    "            idx_list[0] = i - 1 if i > 0 else None\n",
    "        else:\n",
    "            idx_list[2] = i\n",
    "            idx_list[3] = i + 1 if i + 1 < len(slope) else None\n",
    "            break\n",
    "    new_idx_list = []\n",
    "    for i in range(len(idx_list)):\n",
    "        idx = idx_list[i]\n",
    "        if idx is not None:\n",
    "            new_coor_list.append(coor_list[idx])\n",
    "            new_idx_list.append(i+1)\n",
    "    return new_coor_list, new_idx_list\n",
    "\n",
    "gt_parent = \"/home/automan/wuguanjie/CULane_path\"\n",
    "pred_parent = \"/home/automan/wuguanjie/SCNN_Pytorch/experiments/exp_CU_baseline_flip_sr2211_GELU_se/coord_output\"\n",
    "saving_path = \"/home/automan/wuguanjie/exp_CU_baseline_flip_sr2211_GELU_se\"\n",
    "\n",
    "test_folder_list = glob.glob(os.path.join(pred_parent, \"*\"))\n",
    "for driver_folder in test_folder_list:\n",
    "    driver_folder_name = os.path.basename(driver_folder)\n",
    "    full_driver_folder_name = os.path.join(pred_parent, driver_folder_name)\n",
    "    timestamp_folder_list = glob.glob(os.path.join(full_driver_folder_name,\"*\"))\n",
    "    for timestamp_folder in timestamp_folder_list:\n",
    "        frame_file_list = glob.glob(os.path.join(timestamp_folder, \"*\"))\n",
    "        frame_file_list.sort()\n",
    "        for frame_file in frame_file_list:\n",
    "            frame_txt_name = os.path.basename(frame_file)\n",
    "            frame_num = frame_txt_name.split(\".\")[0]\n",
    "            timestamp = os.path.basename(timestamp_folder)\n",
    "            gt_im_path = os.path.join(gt_parent, driver_folder_name, timestamp, frame_num +\".jpg\")\n",
    "            gt_data_path = os.path.join(gt_parent, driver_folder_name, timestamp, frame_txt_name)\n",
    "            pred_data_path = frame_file\n",
    "            saving_folder_path = os.path.join(saving_path, driver_folder_name, timestamp)\n",
    "            if not os.path.exists(saving_folder_path):\n",
    "                os.makedirs(saving_folder_path)\n",
    "            saving_file_path = os.path.join(saving_folder_path, frame_num + \".jpg\")\n",
    "            #reading image\n",
    "            im = cv2.imread(gt_im_path)\n",
    "            # im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            pred_im = im\n",
    "            gt_im = im.copy()\n",
    "\n",
    "            # reading gt data and pred data\n",
    "            with open(pred_data_path, \"r\") as pred_f:\n",
    "                pred_data = pred_f.readlines()\n",
    "            with open(gt_data_path, \"r\") as gt_f:\n",
    "                gt_data = gt_f.readlines()\n",
    "\n",
    "            #data preprocessing\n",
    "            gt_coords_list = []\n",
    "            for l in gt_data:\n",
    "                tmp_data = l.split()\n",
    "                tmp_coords = []\n",
    "                for idx in range(0, len(tmp_data), 2):\n",
    "                    tmp_coords.append([int(float(tmp_data[idx])), int(tmp_data[idx + 1])])\n",
    "                gt_coords_list.append(tmp_coords)\n",
    "\n",
    "            pred_coords_list = []\n",
    "            for l in pred_data:\n",
    "                tmp_data = l.split()\n",
    "                tmp_coords = []\n",
    "                for idx in range(0, len(tmp_data), 2):\n",
    "                    tmp_coords.append([int(float(tmp_data[idx])), int(tmp_data[idx + 1])])\n",
    "                pred_coords_list.append(tmp_coords)\n",
    "            \n",
    "            # plotting data on image\n",
    "            new_gt_coords_list, gt_idx_list = check_lane_idx(gt_coords_list)\n",
    "            new_pred_coords_list, pred_idx_list = check_lane_idx(pred_coords_list)\n",
    "            for i in range(len(new_gt_coords_list)):\n",
    "                gt_coords = new_gt_coords_list[i]\n",
    "                lane_idx = gt_idx_list[i]\n",
    "                colour = color_map[lane_idx]\n",
    "                for idx, (x, y) in enumerate(gt_coords):\n",
    "                    if idx+1 < len(gt_coords):\n",
    "                        sp = gt_coords[idx]\n",
    "                        ep = gt_coords[idx+1]\n",
    "                        cv2.line(gt_im, sp, ep, colour, 3)\n",
    "\n",
    "            for i in range(len(new_pred_coords_list)):\n",
    "                pred_coords = new_pred_coords_list[i]\n",
    "                lane_idx = pred_idx_list[i]\n",
    "                colour = color_map[lane_idx]\n",
    "                for idx, (x, y) in enumerate(pred_coords):\n",
    "                    if idx+1 < len(pred_coords):\n",
    "                        sp = pred_coords[idx]\n",
    "                        ep = pred_coords[idx+1]\n",
    "                        cv2.line(pred_im, sp, ep, colour, 3)\n",
    "\n",
    "            vis = np.concatenate((pred_im, gt_im), axis=1)\n",
    "            cv2.imwrite(saving_file_path, vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the output from combined_dataloader to make sure that the output is correct\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.transforms import *\n",
    "import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define your data transformation\n",
    "resize_shape = (512,288)\n",
    "dataset_name = \"combined\"\n",
    "mean = (0.3598, 0.3653, 0.3662)\n",
    "std = (0.2573, 0.2663, 0.2756)\n",
    "\n",
    "# mean = (0.485, 0.456, 0.406)\n",
    "# std = (0.229, 0.224, 0.225)\n",
    "transform_train = Compose(\n",
    "    Resize(resize_shape, dataset_name),\n",
    "    # ColorJitter(),\n",
    "    RandomFlip(),\n",
    "    Rotation(2),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=mean, std=std),\n",
    ")\n",
    "\n",
    "train_dataset = dataset.combined_dataloader(\n",
    "    \"/home/automan/wuguanjie/SCNN_Pytorch/dataset/combined_train_gt.txt\",\n",
    "    \"train\",\n",
    "    \"combined\",\n",
    "    transform_train,\n",
    ")\n",
    "\n",
    "# Load your data using a DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=train_dataset.collate,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "# Get a batch of data samples\n",
    "for batch_idx, sample in enumerate(train_loader):\n",
    "    img = sample[\"img\"]\n",
    "    segLabel = sample[\"segLabel\"]\n",
    "    # Plot the transformed images\n",
    "    for j in range(img.shape[0]):\n",
    "        loaded_img = img[j].permute(1, 2, 0)\n",
    "        # loaded_img = cv2.cvtColor(loaded_img.numpy(), cv2.COLOR_BGR2RGB)\n",
    "        gt = segLabel[j]\n",
    "        plt.imshow(gt)\n",
    "        plt.show()\n",
    "        plt.imshow(loaded_img)\n",
    "        plt.show()\n",
    "    # Stop after a certain number of batches\n",
    "    if batch_idx == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising the training semantic map\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the file\n",
    "#CULane\n",
    "# img_path = \"/home/automan/wuguanjie/CULane_path/driver_23_30frame/05151652_0423.MP4/00630.jpg\"\n",
    "# gt_path = \"/home/automan/wuguanjie/CULane_path/laneseg_label_w16/driver_23_30frame/05151652_0423.MP4/00630.png\"\n",
    "#TuSimple\n",
    "img_path = \"/home/automan/wuguanjie/TuSimple/train/clips/0313-1/19080/20.jpg\"\n",
    "gt_path = \"/home/automan/wuguanjie/TuSimple/train/seg_label/0313-1/19080/20.png\"\n",
    "semantic_map = cv2.imread(gt_path)[:,:,0]\n",
    "img = cv2.imread(img_path)\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# Define color map\n",
    "color_map = {\n",
    "    0: [0,0,0], #black\n",
    "    1: [255, 0, 0],  # Blue\n",
    "    2: [0, 255, 0],  # Green\n",
    "    3: [0, 0, 255],  # Red\n",
    "    4: [0, 255, 255]  # Yellow\n",
    "}\n",
    "\n",
    "# Create example semantic map with 4 classes\n",
    "# semantic_map = np.random.randint(4, size=(256, 256))\n",
    "\n",
    "# Convert semantic map to color image using color map\n",
    "color_semantic_map = np.zeros((semantic_map.shape[0], semantic_map.shape[1], 3), dtype=np.uint8)\n",
    "# cv2.circle(img,(444,260),radius = 50, color = (255,255,255),thickness=-1) #269,710 710-260, 444-269\n",
    "for label in color_map:\n",
    "    color_semantic_map[semantic_map == label] = color_map[label]\n",
    "combined_img = np.vstack((img, color_semantic_map))\n",
    "cv2.imwrite(\"/home/automan/wuguanjie/report_vis/gt_label.jpg\", combined_img)\n",
    "plt.imshow(combined_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising how to categorise ego lane, left & right lane\n",
    "label = {\"lanes\": [[-2, -2, 444, 485, 519, 535, 540, 540, 540, 539, 532, 524, 517, 510, 503, 496, 489, 482, 475, 468, 461, 453, 446, 439, 432, 425, 418, 411, 404, 397, 390, 383, 375, 368, 361, 354, 347, 340, 333, 326, 319, 312, 304, 297, 290, 283, 276, 269], [-2, 460, 536, 569, 603, 636, 666, 691, 715, 740, 757, 774, 791, 808, 825, 842, 859, 875, 888, 901, 914, 927, 940, 953, 966, 979, 992, 1005, 1019, 1032, 1045, 1058, 1071, 1084, 1097, 1110, 1123, 1136, 1149, 1162, 1175, 1188, 1201, 1214, 1228, 1241, -2, -2], [-2, -2, -2, 426, 437, 434, 424, 406, 383, 360, 336, 308, 281, 254, 227, 200, 173, 145, 118, 91, 64, 37, 10, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2], [-2, 518, 580, 642, 700, 755, 810, 859, 897, 934, 972, 1010, 1047, 1085, 1123, 1160, 1198, 1236, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]], \"h_samples\": [240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710], \"raw_file\": \"clips/0313-1/19080/20.jpg\"}\n",
    "\n",
    "# ---------- clean and sort lanes -------------\n",
    "lanes = []\n",
    "_lanes = []\n",
    "slope = []  # identify 1st, 2nd, 3rd, 4th lane through slope\n",
    "for i in range(len(label[\"lanes\"])):\n",
    "    l = [\n",
    "        (x, y)\n",
    "        for x, y in zip(label[\"lanes\"][i], label[\"h_samples\"])\n",
    "        if x >= 0\n",
    "    ]\n",
    "    if len(l) > 1:\n",
    "        _lanes.append(l)\n",
    "        print(\"l[-1][1]\", l[-1][1])\n",
    "        print(\"l[0][1]\", l[0][1])\n",
    "        print(\"l[0][0]\",l[0][0])\n",
    "        print(\"l[-1][0]\",l[-1][0])\n",
    "        slope.append(\n",
    "            np.arctan2(l[-1][1] - l[0][1], l[0][0] - l[-1][0])\n",
    "            / np.pi\n",
    "            * 180\n",
    "        )\n",
    "\n",
    "_lanes = [_lanes[i] for i in np.argsort(slope)]\n",
    "slope = [slope[i] for i in np.argsort(slope)]\n",
    "\n",
    "idx_1 = None\n",
    "idx_2 = None\n",
    "idx_3 = None\n",
    "idx_4 = None\n",
    "for i in range(len(slope)):\n",
    "    if slope[i] <= 90:\n",
    "        idx_2 = i\n",
    "        idx_1 = i - 1 if i > 0 else None\n",
    "    else:\n",
    "        idx_3 = i\n",
    "        idx_4 = i + 1 if i + 1 < len(slope) else None\n",
    "        break\n",
    "lanes.append([] if idx_1 is None else _lanes[idx_1])\n",
    "lanes.append([] if idx_2 is None else _lanes[idx_2])\n",
    "lanes.append([] if idx_3 is None else _lanes[idx_3])\n",
    "lanes.append([] if idx_4 is None else _lanes[idx_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising segmantic map\n",
    "from utils.transforms import *\n",
    "from model_segformer import segformer\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision.transforms import Normalize as Normalize_th\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from utils.prob2lines import getLane\n",
    "\n",
    "with open(\"/home/automan/wuguanjie/SCNN_Pytorch/experiments/exp_TU1_Segformer_mitb0_tensorboard/cfg.json\") as f:\n",
    "    exp_cfg = json.load(f)\n",
    "model_config = exp_cfg['MODEL_CONFIG']\n",
    "model = segformer(model_config, \"Tusimple\",pretrained=True)\n",
    "save_name = \"/home/automan/wuguanjie/SCNN_Pytorch/experiments/exp_TU1_Segformer_mitb0_tensorboard/exp_TU1_Segformer_mitb0_tensorboard_best.pth\"\n",
    "save_dict = torch.load(save_name, map_location='cpu')\n",
    "model.load_state_dict(save_dict['net'])\n",
    "model = model.to('cuda:2')\n",
    "model.eval()\n",
    "#resize\n",
    "pred_img = cv2.imread(\"/home/automan/wuguanjie/TuSimple/train/clips/0531/1492638208126576446/20.jpg\")\n",
    "print(pred_img.shape)\n",
    "pred_img = cv2.resize(pred_img,(512,288))\n",
    "\n",
    "#to tensor\n",
    "pred_img = pred_img.transpose(2, 0, 1)\n",
    "pred_img = torch.from_numpy(pred_img).type(torch.float) / 255.\n",
    "\n",
    "#normalization\n",
    "mean=(0.485, 0.456, 0.406)\n",
    "std=(0.229, 0.224, 0.225)\n",
    "transform = Normalize_th(mean, std)\n",
    "pred_img = transform(pred_img)\n",
    "pred_img = torch.unsqueeze(pred_img, 0)\n",
    "pred_img = pred_img.to('cuda:2')\n",
    "output = model(pred_img)\n",
    "seg_pred = F.softmax(output[0], dim=1)\n",
    "seg_pred = torch.squeeze(seg_pred, 0)\n",
    "seg_pred = seg_pred.detach().cpu().numpy()\n",
    "exist_pred = output[1].detach().cpu().numpy()[0]\n",
    "# seg_pred = np.ascontiguousarray(np.transpose(seg_pred, (1, 2, 0)))\n",
    "exist = [1 if exist_pred[i] > 0.1 else 0 for i in range(len(exist_pred))]\n",
    "print(exist)\n",
    "lane_coords, lane_idx = getLane.prob2lines_tusimple(seg_pred, exist, resize_shape=(720,1280),y_px_gap=10, pts = 56)\n",
    "for i in range(len(lane_coords)):\n",
    "    lane_coords = sorted(lane_coords, key= lambda pair:pair[1])\n",
    "print(len(lane_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising the training semantic map\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color_map = {\n",
    "    0: [0,0,0], #black\n",
    "    1: [255, 255, 255],  # white\n",
    "}\n",
    "\n",
    "tmp_seg_pred = np.ascontiguousarray(np.transpose(seg_pred, (1, 2, 0)))\n",
    "\n",
    "for i in range(5):\n",
    "    semantic_map = tmp_seg_pred[:,:,i]\n",
    "    semantic_map = semantic_map > 0.3\n",
    "    color_semantic_map = np.zeros((semantic_map.shape[0], semantic_map.shape[1], 3), dtype=np.uint8)\n",
    "    for label in color_map:\n",
    "        color_semantic_map[semantic_map == label] = color_map[label]\n",
    "    saving_path = \"/home/automan/wuguanjie/report_vis/{}.jpg\".format(str(i))\n",
    "    cv2.imwrite(saving_path,color_semantic_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising the binary semantic map\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color_map = {\n",
    "    0: [0,0,0], #black\n",
    "    1: [255, 255, 255],  # white\n",
    "}\n",
    "\n",
    "tmp_seg_pred = np.ascontiguousarray(np.transpose(seg_pred, (1, 2, 0)))\n",
    "semantic_map1 = tmp_seg_pred[:,:,1] > 0.3\n",
    "semantic_map2 = tmp_seg_pred[:,:,2] > 0.3\n",
    "semantic_map3 = tmp_seg_pred[:,:,3] > 0.3\n",
    "semantic_map4 = tmp_seg_pred[:,:,4] > 0.3\n",
    "semantic_map = semantic_map1 | semantic_map2 | semantic_map3 | semantic_map4\n",
    "color_semantic_map = np.zeros((semantic_map1.shape[0], semantic_map1.shape[1], 3), dtype=np.uint8)\n",
    "for label in color_map:\n",
    "    color_semantic_map[semantic_map == label] = color_map[label]\n",
    "saving_path = \"/home/automan/wuguanjie/report_vis/{}.jpg\".format(\"binary_segmentation_output\")\n",
    "plt.imshow(color_semantic_map)\n",
    "cv2.imwrite(saving_path,color_semantic_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising random flip\n",
    "from utils.transforms.transforms import *\n",
    "from utils.transforms.data_augmentation import *\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "color_map = {\n",
    "    0: [0,0,0], #black\n",
    "    1: [255, 0, 0],  # Blue\n",
    "    2: [0, 255, 0],  # Green\n",
    "    3: [0, 0, 255],  # Red\n",
    "    4: [0, 255, 255]  # Yellow\n",
    "}\n",
    "img = cv2.imread(\"/home/automan/wuguanjie/TuSimple/train/clips/0530/1492626047222176976_0/20.jpg\")\n",
    "gt = cv2.imread(\"/home/automan/wuguanjie/TuSimple/train/seg_label/0530/1492626047222176976_0/20.png\")[:,:,0]\n",
    "sample = {}\n",
    "sample[\"img\"] = img\n",
    "sample[\"segLabel\"] = gt\n",
    "sample[\"exist\"] = [1,2,3,4]\n",
    "flip = RandomFlip(0.5)\n",
    "flipped_sample = flip(sample)\n",
    "flipped_img = flipped_sample[\"img\"]\n",
    "flipped_gt = flipped_sample[\"segLabel\"]\n",
    "flipped_exist = flipped_sample[\"exist\"]\n",
    "print(flipped_exist)\n",
    "color_segmentation_map = np.zeros((flipped_img.shape[0], flipped_img.shape[1],3), dtype=np.uint8)\n",
    "for label in color_map:\n",
    "    color_segmentation_map[flipped_gt == label] = color_map[label]\n",
    "\n",
    "vis = np.vstack((flipped_img, color_segmentation_map))\n",
    "\n",
    "not_flipped_img = sample[\"img\"]\n",
    "not_flipped_color_segmentation_map = np.zeros((not_flipped_img.shape[0], not_flipped_img.shape[1],3), dtype=np.uint8)\n",
    "not_flipped_gt = sample[\"segLabel\"]\n",
    "for label in color_map:\n",
    "    not_flipped_color_segmentation_map[not_flipped_gt == label] = color_map[label]\n",
    "vis_not_flipped = np.vstack((not_flipped_img, not_flipped_color_segmentation_map))\n",
    "\n",
    "final_vis = np.hstack((vis_not_flipped, vis))\n",
    "cv2.imwrite(\"/home/automan/wuguanjie/report_vis/flipped_and_not_flipped.jpg\", final_vis)\n",
    "plt.imshow(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising colorjitter\n",
    "from utils.transforms.transforms import *\n",
    "from utils.transforms.data_augmentation import *\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"/home/automan/wuguanjie/TuSimple/train/clips/0530/1492626047222176976_0/20.jpg\")\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "sample = {}\n",
    "sample[\"img\"] = img\n",
    "vis = img\n",
    "for i in range(4):\n",
    "    illu_change = ColorJitter()\n",
    "    changed_sample = illu_change(sample)\n",
    "    changed_img = changed_sample[\"img\"]\n",
    "    vis = np.hstack((vis, changed_img))\n",
    "cv2.imwrite(\"/home/automan/wuguanjie/report_vis/color_jitter.png\", vis)\n",
    "plt.imshow(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising rotation\n",
    "from utils.transforms.transforms import *\n",
    "from utils.transforms.data_augmentation import *\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "color_map = {\n",
    "    0: [0,0,0], #black\n",
    "    1: [255, 0, 0],  # Blue\n",
    "    2: [0, 255, 0],  # Green\n",
    "    3: [0, 0, 255],  # Red\n",
    "    4: [0, 255, 255]  # Yellow\n",
    "}\n",
    "img = cv2.imread(\"/home/automan/wuguanjie/TuSimple/train/clips/0530/1492626047222176976_0/20.jpg\")\n",
    "gt = cv2.imread(\"/home/automan/wuguanjie/TuSimple/train/seg_label/0530/1492626047222176976_0/20.png\")[:,:,0]\n",
    "sample = {}\n",
    "sample[\"img\"] = img\n",
    "sample[\"segLabel\"] = gt\n",
    "flip = Rotation(2)\n",
    "flipped_sample = flip(sample)\n",
    "flipped_img = flipped_sample[\"img\"]\n",
    "flipped_gt = flipped_sample[\"segLabel\"]\n",
    "color_segmentation_map = np.zeros((flipped_img.shape[0], flipped_img.shape[1],3), dtype=np.uint8)\n",
    "for label in color_map:\n",
    "    color_segmentation_map[flipped_gt == label] = color_map[label]\n",
    "\n",
    "vis = np.vstack((flipped_img, color_segmentation_map))\n",
    "# cv2.imwrite(\"/home/automan/wuguanjie/report_vis/not_flipped.jpg\", vis)\n",
    "plt.imshow(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize RELU function\n",
    "# plot inputs and outputs\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# rectified linear function\n",
    "def rectified(x):\n",
    " return max(0.0, x)\n",
    " \n",
    "# define a series of inputs\n",
    "series_in = [x for x in range(-10, 11)]\n",
    "# calculate outputs for our inputs\n",
    "series_out = [rectified(x) for x in series_in]\n",
    "# line plot of raw inputs to rectified outputs\n",
    "plt.plot(series_in, series_out)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "177fd3b3e8a9acd141a8204cd1d3def8a31236eeda8acb6b43a40c68f1337a89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
